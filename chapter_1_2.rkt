#lang racket

#| Exercise 1.9.  Each of the following two procedures defines a method for adding two positive 
integers in terms of the procedures inc, which increments its argument by 1, and dec, which 
decrements its argument by 1.

Using the substitution model, illustrate the process generated by each procedure in evaluating 
(+ 4 5). Are these processes iterative or recursive?
--
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(+ 4 5)
(inc (+ 3 5))
(inc (inc (+ 2 5)))
(inc (inc (inc (+ 1 5))))
(inc (inc (inc (inc (+ 0 5)))))
(inc (inc (inc (inc 5))))
(inc (inc (inc 6)))
(inc (inc 7))
(inc 8)
9
recursive

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))

(+ 4 5)
(+ 3 6)
(+ 2 7)
(+ 1 8)
(+ 0 9)
9
iterative
|#

#| Exercise 1.10.  The following procedure computes a mathematical function called Ackermann's 
function.

(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))

What are the values of the following expressions?

(A 1 10)
1024

(A 2 4)
65536

(A 3 3)
65536

Consider the following procedures, where A is the procedure defined above:

(define (f n) (A 0 n))

(define (g n) (A 1 n))

(define (h n) (A 2 n))

(define (k n) (* 5 n n))

Give concise mathematical definitions for the functions computed by the procedures f, g, and h for 
positive integer values of n. For example, (k n) computes 5n2. 

(f n) computes 2n
(g n) computes 2^n
(h n) computes 2^(h n-1)
|#

(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))

(A 1 10)
(A 2 4)
(A 3 3)

#| Exercise 1.11.  A function f is defined by the rule that 

f(n) = n if n<3 and 
f(n) = f(n - 1) + 2f(n - 2) + 3f(n - 3) if n> 3. 

Write a procedure that computes f by means of a recursive process. Write a procedure that 
computes f by means of an iterative process. |#

(define (f-rec n)
  (if (< n 3)
      n
      (+ (f-rec (- n 1)) (* 2 (f-rec (- n 2))) (* 3 (f-rec (- n 3))))))

(f-rec 10)

(define (f-iter n)
  (define (iter n1 n2 n3 count)
    (if (= count n)
        n1
        (iter (+ n1 (* 2 n2) (* 3 n3)) n1 n2 (+ count 1))))
  (if (< n 3)
      n
      (iter 2 1 0 2)))

(f-iter 10)

#| Exercise 1.12.  The following pattern of numbers is called Pascal's triangle.

The numbers at the edge of the triangle are all 1, and each number inside the triangle is the sum of
the two numbers above it.35 Write a procedure that computes elements of Pascal's triangle by means 
of a recursive process. |#

(define (pascal row n)
  (cond ((or (< n 1) (> n row) (< n 1)) 0)
        ((= row 1) 1)
        (else (+ (pascal (- row 1) (- n 1)) (pascal (- row 1) n)))))

(pascal 5 3)
(pascal 6 3)

#| Exercise 1.13.  Prove that Fib(n) is the closest integer to theta^n/sqrt(5), 
where theta = (1 + sqrt(5))/2. 
Hint: Let psi = (1 - sqrt(5))/2. Use induction and the definition of the Fibonacci numbers 
(see section 1.2.2) to prove that Fib(n) = (theta^n - psi^n)/sqrt(5).

See paper
|#

#| Exercise 1.14.  Draw the tree illustrating the process generated by the count-change procedure of
section 1.2.2 in making change for 11 cents. What are the orders of growth of the space and number of
steps used by this process as the amount to be changed increases? |#

#| Exercise 1.15.  The sine of an angle (specified in radians) can be computed by making use of the 
approximation sin x ~= x if x is sufficiently small, and the trigonometric identity

sin(r) = 3 * sin(r/3) - 4 * sin^3(r/3)

to reduce the size of the argument of sin. (For purposes of this exercise an angle is considered 
"sufficiently small" if its magnitude is not greater than 0.1 radians.) These ideas are incorporated
in the following procedures:

(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))

a.  How many times is the procedure p applied when (sine 12.15) is evaluated?

6

b.  What is the order of growth in space and number of steps (as a function of a) used by the process
generated by the sine procedure when (sine a) is evaluated? 

number of steps: O(log a)
space: It looks like it grows logarithmically, at least with applicative order. We add another p
  function call with each step. 
|#

(define (square n) (* n n)) 
(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))

#| Exercise 1.16.  Design a procedure that evolves an iterative exponentiation process that uses
successive squaring and uses a logarithmic number of steps, as does fast-expt. (Hint: Using the
observation that (bn/2)2 = (b2)n/2, keep, along with the exponent n and the base b, an additional
state variable a, and define the state transformation in such a way that the product a bn is
unchanged from state to state. At the beginning of the process a is taken to be 1, and the answer is
given by the value of a at the end of the process. In general, the technique of defining an 
invariant quantity that remains unchanged from state to state is a powerful way to think about the 
design of iterative algorithms.) |#

(define (fast-iterative-expt b n)
  (define (iter a b n)
    (if (= n 0)
        a
        (if (even? n)
            (iter a (square b) (/ n 2))
            (iter (* a b) b (- n 1)))))
  (iter 1 b n))

(fast-iterative-expt 3 6)
(fast-iterative-expt 2 10)

#| Exercise 1.17.  The exponentiation algorithms in this section are based on performing
exponentiation by means of repeated multiplication. In a similar way, one can perform integer
multiplication by means of repeated addition. The following multiplication procedure (in which it is
assumed that our language can only add, not multiply) is analogous to the expt procedure:

(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))

This algorithm takes a number of steps that is linear in b. Now suppose we include, together with
addition, operations double, which doubles an integer, and halve, which divides an (even) integer by
2. Using these, design a multiplication procedure analogous to fast-expt that uses a logarithmic 
number of steps. |#

(define (double x) (+ x x))
(define (halve x) (/ x 2))

(define (fast-* a b)
  (cond ((= b 0) 0)
        ((even? b) (fast-* (double a) (halve b)))
        (else (+ a (fast-* a (- b 1))))))

(fast-* 6 7)
(fast-* 25 40)

#| Exercise 1.18.  Using the results of exercises 1.16 and 1.17, devise a procedure that generates 
an iterative process for multiplying two integers in terms of adding, doubling, and halving and uses
a logarithmic number of steps. |#

(define (fast-iterative-* a b)
  (define (iter product a b)
    (if (= b 0) 
        product
        (if (even? b)
            (iter product (double a) (halve b))
            (iter (+ product a) a (- b 1)))))
  (iter 0 a b))

(fast-iterative-* 7 8)
(fast-iterative-* 33 5)

#| Exercise 1.19 |#

#| Exercise 1.20.  The process that a procedure generates is of course dependent on the rules used 
by the interpreter. As an example, consider the iterative gcd procedure given above. Suppose we were 
to interpret this procedure using normal-order evaluation, as discussed in section 1.1.5. 
(The normal-order-evaluation rule for if is described in exercise 1.5.) Using the substitution 
method (for normal order), illustrate the process generated in evaluating (gcd 206 40) and indicate 
the remainder operations that are actually performed. How many remainder operations are actually 
performed in the normal-order evaluation of (gcd 206 40)? In the applicative-order evaluation?

normal:
(gcd 206 40)
(if (= 40 0)
    206
    (gcd 40 (remainder 206 40)))

(gcd 40 (remainder 206 40))
(if (= (remainder 206 40) 0)
    40
    (gcd (remainder 206 40)
         (remainder 40 (remainder 206 40))))

evaluate 1 remainder in predicate: 6 != 0

(gcd (remainder 206 40)
     (remainder 40 (remainder 206 40)))
(if (= (remainder 40 (remainder 206 40)) 0)
    (remainder 206 40)
    (gcd (remainder 40 (remainder 206 40))
         (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))

evaluate 2 remainders in predicate: 4 != 0

(gcd (remainder 40 (remainder 206 40))
     (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))
(if (= (remainder (remainder 206 40) (remainder 40 (remainder 206 40))) 0)
    (remainder 40 (remainder 206 40))
    (gcd (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
         (remainder (remainder 40 (remainder 206 40))
                    (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))))

evaluate 4 remainders in predicate: 2 != 0

(gcd (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
     (remainder (remainder 40 (remainder 206 40))
                (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))
(if (= (remainder (remainder 40 (remainder 206 40))
                  (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))
       0)
    (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
    (gcd (remainder (remainder 40 (remainder 206 40))
                    (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))
         (remainder (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
                    (remainder (remainder 40 (remainder 206 40))
                               (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))))

evaluate 7 remainders in predicate: 0 = 0

(remainder (remainder 206 40) (remainder 40 (remainder 206 40)))
2

4 more remainders

18 total remainder operations?

applicative:
(gcd 206 40)
(if (= 40 0)
    206
    (gcd 40 (remainder 206 40)))
(gcd 40 (remainder 206 40))
(gcd 40 6)
(if (= 6 0)
    40
    (gcd 6 (remainder 40 6)))
(gcd 6 (remainder 40 6))
(gcd 6 4)
(if (= 4 0)
    5
    (gcd 4 (remainder 6 4)))
(gcd 4 (remainder 6 4))
(gcd 4 2)
(if (= 2 0)
    4
    (gcd 2 (remainder 4 2)))
(gcd 2 (remainder 4 2))
(gcd 2 0)
(if (= 0 0)
    2
    (gc 0 (remainder 2 0)))
2

4 remainder operations

|#

#| Exercise 1.21.  Use the smallest-divisor procedure to find the smallest divisor of each of the 
following numbers: 199, 1999, 19999. |#

(define (smallest-divisor n)
  (find-divisor n 2))
(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))
(define (divides? a b)
  (= (remainder b a) 0))

(smallest-divisor 199)
(smallest-divisor 1999)
(smallest-divisor 19999)

#| Exercise 1.22.  Most Lisp implementations include a primitive called runtime that returns an 
integer that specifies the amount of time the system has been running (measured, for example, in 
microseconds). The following timed-prime-test procedure, when called with an integer n, prints n 
and checks to see if n is prime. If n is prime, the procedure prints three asterisks followed by the 
amount of time used in performing the test. |#

(define runtime current-inexact-milliseconds)
(define (prime? n)
  (= n (smallest-divisor n)))

(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time)) '()))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))

#| Using this procedure, write a procedure search-for-primes that checks the primality of consecutive
odd integers in a specified range. Use your procedure to find the three smallest primes larger than 
1000; larger than 10,000; larger than 100,000; larger than 1,000,000. Note the time needed to test 
each prime. Since the testing algorithm has order of growth of O(sqrt(n)), you should expect that 
testing for primes around 10,000 should take about sqrt(10) times as long as testing for primes 
around 1000. Do your timing data bear this out? How well do the data for 100,000 and 1,000,000 
support the sqrt(n) prediction? Is your result compatible with the notion that programs on your 
machine run in time proportional to the number of steps required for the computation? |#

(define (search-for-primes number-of-primes lower prime-f)
  (define (report-prime n elapsed-time)
    (newline)
    (display n)
    (display " *** ")
    (display elapsed-time))
  (define (iter number-of-primes current-x start-time)
    (cond ((> number-of-primes 0) 
           (cond ((prime-f current-x) 
                  (report-prime current-x (- (runtime) start-time))
                  (iter (- number-of-primes 1) (+ current-x 1) (runtime)))
                 (else (iter number-of-primes (+ current-x 1) (runtime)))))))
  (iter number-of-primes lower (runtime)))

(search-for-primes 10 2 prime?)
(search-for-primes 3 1000 prime?)
(search-for-primes 3 10000 prime?)
(search-for-primes 3 100000 prime?)
(search-for-primes 3 1000000 prime?)

#| The numbers match up pretty neatly. Each factor of 10 increases the caclulation time by about
sqrt(10) |#

#| Exercise 1.23.  The smallest-divisor procedure shown at the start of this section does lots 
of needless testing: After it checks to see if the number is divisible by 2 there is no point 
in checking to see if it is divisible by any larger even numbers. This suggests that the values 
used for test-divisor should not be 2, 3, 4, 5, 6, ..., but rather 2, 3, 5, 7, 9, .... To 
implement this change, define a procedure next that returns 3 if its input is equal to 2 and 
otherwise returns its input plus 2. Modify the smallest-divisor procedure to use (next 
test-divisor) instead of (+ test-divisor 1). With timed-prime-test incorporating this modified 
version of smallest-divisor, run the test for each of the 12 primes found in exercise 1.22. Since 
this modification halves the number of test steps, you should expect it to run about twice as 
fast. Is this expectation confirmed? If not, what is the observed ratio of the speeds of the 
two algorithms, and how do you explain the fact that it is different from 2? |#

(newline)

(define (next x) (if (= x 2) 3 (+ 2 x)))

(define (faster-smallest-divisor n)
  (faster-find-divisor n 2))
(define (faster-find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (faster-find-divisor n (next test-divisor)))))

(define (faster-prime? n)
  (= n (faster-smallest-divisor n)))

(search-for-primes 3 1000 faster-prime?)
(search-for-primes 3 10000 faster-prime?)
(search-for-primes 3 100000 faster-prime?)
(search-for-primes 3 1000000 faster-prime?)

#| It is not quite twice as fast. t(faster)/t(original) is closer to .6 than .5
I would guess that each function call to next adds about 20% extra time over each addition. Not
totally sure that's the reason. |#

#| Exercise 1.24.  Modify the timed-prime-test procedure of exercise 1.22 to use fast-prime? 
(the Fermat method), and test each of the 12 primes you found in that exercise. Since the Fermat 
test has theta(log n) growth, how would you expect the time to test primes near 1,000,000 to 
compare with the time needed to test primes near 1000? Do your data bear this out? Can you 
explain any discrepancy you find? |#

(newline)

(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))

(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))

(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))

(search-for-primes 3 1000 (lambda (n) (fast-prime? n 10)))
(search-for-primes 3 10000 (lambda (n) (fast-prime? n 10)))
(search-for-primes 3 100000 (lambda (n) (fast-prime? n 10)))
(search-for-primes 3 1000000 (lambda (n) (fast-prime? n 10)))
(search-for-primes 3 10000000 (lambda (n) (fast-prime? n 10)))
(search-for-primes 3 100000000 (lambda (n) (fast-prime? n 10)))

#| The tests ran in about the expected time--each time we multiply n by 10, the time
to run increases by about the same constant amount |#

#| Exercise 1.25.  Alyssa P. Hacker complains that we went to a lot of extra work in writing expmod.
After all, she says, since we already know how to compute exponentials, we could have simply written

(define (expmod base exp m)
  (remainder (fast-expt base exp) m))

Is she correct? Would this procedure serve as well for our fast prime tester? Explain.
|#

#| Exercise 1.27.  Demonstrate that the Carmichael numbers listed in footnote 47 really do fool 
the Fermat test. That is, write a procedure that takes an integer n and tests whether an is 
congruent to a modulo n for every a<n, and try your procedure on the given Carmichael numbers. |#

(newline)
(newline)

(define (carmichael-test n)
  (define (iter x)
    (cond ((= x n) true)
          ((= (expmod x n n) x) (iter (+ x 1)))
          (else false)))
  (iter 1))

(carmichael-test 12)
(carmichael-test 100)
(carmichael-test 561)
(carmichael-test 1105)
(carmichael-test 1709)
(carmichael-test 2465)
(carmichael-test 2821)
(carmichael-test 6601)
(carmichael-test 6600)
